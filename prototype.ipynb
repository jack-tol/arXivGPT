{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "\n",
    "# Third-party library imports for arXiv API, document handling, and embedding\n",
    "import arxiv\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Initialize components\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "embedding_model = HuggingFaceEmbeddings()\n",
    "metadata_vector_store = PineconeVectorStore.from_existing_index(embedding=embedding_model, index_name=\"arxiv-metadata\")\n",
    "chunks_vector_store = PineconeVectorStore.from_existing_index(embedding=embedding_model, index_name=\"arxiv-project-chunks\")\n",
    "semantic_chunker = SemanticChunker(embeddings=embedding_model, buffer_size=1, add_start_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top search results based on content and metadata:\n",
      "\n",
      "1: Research Paper Title & Author: Quantifying Quantumness and the Quest for Queens of Quantum by Olivier Giraud, Petr A. Braun, Daniel Braun\n",
      "   Document ID: 1002.2158\n",
      "\n",
      "2: Research Paper Title & Author: Demystifying Quantum Mechanics by Ana Elisa D. Barioni, Felipe B. Mazzi, Elsa Bifano Pimenta, Willian Vieira dos Santos, Marco A. P. Lima\n",
      "   Document ID: 2106.02161\n",
      "\n",
      "3: Research Paper Title & Author: A primer on quantum mechanics and its interpretations by Casey Blood\n",
      "   Document ID: 1001.3080\n",
      "\n",
      "4: Research Paper Title & Author: A glance beyond the quantum model by Miguel Navascues, Harald Wunderlich\n",
      "   Document ID: 0907.0372\n",
      "\n",
      "5: Research Paper Title & Author: Physics as quantum information processing by Giacomo Mauro D'Ariano\n",
      "   Document ID: 1012.2597\n",
      "\n",
      "\n",
      "You selected document ID: 1002.2158\n",
      "Downloading Paper\n",
      "Processing & Uploading Paper\n",
      "Paper Uploaded. Please Proceed To Ask Your Question\n",
      "Response from AI: \n",
      "Well, first of all, let me explain to you what a paper is. A paper is a written document that contains information and research on a specific topic. In this case, the topic is related to physics and mathematics.\n",
      "\n",
      "The paper is written by a group of authors, namely A. Davis, R. Delbourgo, and P. D. Jarvis. They published their work in a journal called J. Phys. A: Math. Gen in the year 2000. This journal is known for publishing articles related to physics and mathematics.\n",
      "\n",
      "Now, let's look at some of the key concepts in this paper. The first concept is the idea of coherent states. Coherent states are quantum states that have a specific relationship with classical states. They are often used in quantum mechanics to describe the behavior of particles.\n",
      "\n",
      "Next, we have the concept of quadratic programming. This is a mathematical optimization technique that is used to find the optimal solution to a problem. It is often used in engineering, economics, and other fields to find the best possible solution.\n",
      "\n",
      "The paper also discusses the concept of the density matrix, which is a mathematical tool used to describe the state of a quantum system. It is used to calculate the probabilities of different quantum states and to understand the dynamics of these\n"
     ]
    }
   ],
   "source": [
    "def process_and_upload_chunks(document_id):\n",
    "    print(\"Downloading Paper\")\n",
    "    paper = next(arxiv.Client().results(arxiv.Search(id_list=[str(document_id)])))\n",
    "    paper.download_pdf(filename=f\"{document_id}.pdf\")\n",
    "    loader = PyPDFLoader(f\"{document_id}.pdf\")\n",
    "    print(\"Processing & Uploading Paper\")\n",
    "    pages = loader.load_and_split()\n",
    "\n",
    "    chunks = []\n",
    "    for page in pages:\n",
    "        text = page.page_content\n",
    "        chunks.extend(semantic_chunker.split_text(text))\n",
    "    chunks_vector_store.from_texts(texts=chunks, embedding=embedding_model, metadatas=[{\"document_id\": document_id} for _ in chunks], index_name=\"arxiv-project-chunks\")\n",
    "    os.remove(f\"{document_id}.pdf\")\n",
    "    print(\"Paper Uploaded. Please Proceed To Ask Your Question.\")\n",
    "\n",
    "def do_chunks_exist_already(document_id):\n",
    "    filter = {\"document_id\": {\"$eq\": document_id}}\n",
    "    test_query = chunks_vector_store.similarity_search(query=\"Chunks Existence Check\", k=1, filter=filter)\n",
    "    return bool(test_query)\n",
    "\n",
    "def process_user_query(document_id):\n",
    "    context = []\n",
    "    user_query = input(\"Please enter your question:\\n\")\n",
    "    filter = {\"document_id\": {\"$eq\": document_id}}\n",
    "    search_results = chunks_vector_store.similarity_search(query=user_query, k=5, filter=filter)\n",
    "    for doc in search_results:\n",
    "        context.append(doc.page_content)\n",
    "    return context, user_query\n",
    "\n",
    "def query_openai_with_context(context, user_query):\n",
    "    template = \"\"\"Use The Following Context:\n",
    "    Context: {context}\n",
    "    To Answer The Following Question:\n",
    "    {user_query}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    model = OpenAI()\n",
    "    parser = StrOutputParser()\n",
    "    chain = prompt | model | parser\n",
    "    output = chain.invoke({\"context\": context, \"user_query\": user_query})\n",
    "    return output\n",
    "\n",
    "def select_document_from_results(search_results):\n",
    "    if not search_results:\n",
    "        print(\"No search results found.\")\n",
    "        return None\n",
    "    print(\"Top search results based on content and metadata:\\n\")\n",
    "    for i, doc in enumerate(search_results, start=1):\n",
    "        page_content = doc.page_content\n",
    "        document_id = doc.metadata['document_id']\n",
    "        print(f\"{i}: Research Paper Title & Author: {page_content}\\n   Document ID: {document_id}\\n\")\n",
    "    user_choice = int(input(\"Select a paper by entering its number: \")) - 1\n",
    "    if 0 <= user_choice < len(search_results):\n",
    "        selected_doc_id = search_results[user_choice].metadata['document_id']\n",
    "        print(f\"\\nYou selected document ID: {selected_doc_id}\")\n",
    "        return selected_doc_id\n",
    "    else:\n",
    "        print(\"\\nInvalid selection. Please run the process again and select a valid number.\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    initial_query = input(\"Enter the title or topic of the paper you're interested in: \")\n",
    "    search_results = metadata_vector_store.similarity_search(query=initial_query, k=5)\n",
    "    selected_doc_id = select_document_from_results(search_results)\n",
    "    if selected_doc_id:\n",
    "        if not do_chunks_exist_already(selected_doc_id):\n",
    "            process_and_upload_chunks(selected_doc_id)\n",
    "        context, user_query = process_user_query(selected_doc_id)\n",
    "        response = query_openai_with_context(context, user_query)\n",
    "        print(\"Response from AI:\", response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
